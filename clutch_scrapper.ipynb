{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: fake-useragent\n",
      "Successfully installed fake-useragent-1.5.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install selenium-stealth\n",
    "# !pip install fake-useragent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run it to intialize your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium_stealth import stealth\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def start():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"--headless\")  # Uncomment if you want to run headless\n",
    "\n",
    "    # Fake User-Agent\n",
    "    ua = UserAgent()\n",
    "    user_agent = ua.random\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "    # Disable webdriver mode\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    stealth(driver,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "            )\n",
    "    return driver\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract company links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = start()\n",
    "company_links = set()\n",
    "\n",
    "\n",
    "url = \"https://clutch.co/developers?page=1\"\n",
    "driver.get(url)\n",
    "request = driver.page_source\n",
    "soup = BeautifulSoup(request, 'html.parser')\n",
    "\n",
    "for i in range(708):  # here 708 is no. of page\n",
    "    script_tag = soup.find_all(\"script\",type=\"application/ld+json\")\n",
    "\n",
    "    json_data_company = [\n",
    "        json.loads(x.string) for x in script_tag\n",
    "    ]\n",
    "\n",
    "    for d in json_data_company:\n",
    "        if d['@type']=='Organization':\n",
    "            company_links.add(d['url']+'#highlights')\n",
    "        elif d['@type'] == 'CollectionPage':\n",
    "            list_elements = d['mainEntity']['itemListElement']\n",
    "            for item in list_elements:\n",
    "                if item['item']['@type'] == 'Organization':\n",
    "                    company_links.add(item['item']['url']+'#highlights')\n",
    "    driver.quit()\n",
    "    time.sleep(5)\n",
    "    driver = start()\n",
    "    if i+1 != 1:\n",
    "        url = url.split('=')[0] + f'={i+1}'\n",
    "        driver.get(url)\n",
    "        request = driver.page_source\n",
    "        soup = BeautifulSoup(request, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Links to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links saved to links.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(company_links, columns=[\"Links\"])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(\"links.xlsx\", index=False)\n",
    "\n",
    "print(\"Links saved to links.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Links from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links read from links.xlsx:\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"links.xlsx\")\n",
    "\n",
    "# Convert the DataFrame column back to a list\n",
    "company_links = df[\"Links\"].tolist()\n",
    "\n",
    "print(\"Links read from links.xlsx:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now start extracting reviewer's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8001\n",
      "8002\n",
      "8003\n",
      "8004\n",
      "8005\n",
      "8006\n",
      "8007\n",
      "8008\n",
      "8009\n",
      "8010\n",
      "8011\n",
      "8012\n",
      "8013\n",
      "8014\n",
      "8015\n",
      "8016\n",
      "8017\n",
      "8018\n",
      "8019\n",
      "8020\n",
      "8021\n",
      "8022\n",
      "8023\n",
      "8024\n",
      "8025\n",
      "8026\n",
      "8027\n",
      "8028\n",
      "8029\n",
      "8030\n",
      "8031\n",
      "8032\n",
      "8033\n",
      "8034\n",
      "8035\n",
      "8036\n",
      "8037\n",
      "8038\n",
      "8039\n",
      "8040\n",
      "8041\n",
      "8042\n",
      "8043\n",
      "8044\n",
      "8045\n",
      "8046\n",
      "8047\n",
      "8048\n",
      "8049\n",
      "8050\n",
      "8051\n",
      "8052\n",
      "8053\n",
      "8054\n",
      "8055\n",
      "8056\n",
      "8057\n",
      "8058\n",
      "8059\n",
      "8060\n",
      "8061\n",
      "8062\n",
      "8063\n",
      "8064\n",
      "8065\n",
      "8066\n",
      "8067\n",
      "8068\n",
      "8069\n",
      "8070\n",
      "8071\n",
      "8072\n",
      "8073\n",
      "8074\n",
      "8075\n",
      "8076\n",
      "8077\n",
      "8078\n",
      "8079\n",
      "8080\n",
      "8081\n",
      "8082\n",
      "8083\n",
      "8084\n",
      "8085\n",
      "8086\n",
      "8087\n",
      "8088\n",
      "8089\n",
      "8090\n",
      "8091\n",
      "8092\n",
      "8093\n",
      "8094\n",
      "8095\n",
      "8096\n",
      "8097\n",
      "8098\n",
      "8099\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "driver = start()\n",
    "company_no = 8000\n",
    "starting = 8000\n",
    "for k in range(starting,8100): ## till 35 thousands\n",
    "    url = company_links[k]\n",
    "    driver = start()\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    bs = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    try:\n",
    "        try:\n",
    "            max_page = bs.find('span',{'class':'sg-pagination__text'})\n",
    "            max_page = max_page.text.split('of')[1].strip()\n",
    "            max_page = int(max_page)\n",
    "        except:\n",
    "            max_page = 1\n",
    "        \n",
    "\n",
    "        for j in range(max_page):\n",
    "            for div in bs.find_all('div',{'class': \"profile-review__reviewer\"}):\n",
    "                data = {}\n",
    "                name = div.find('div',{'class':'reviewer_card--name'}).text\n",
    "                postion = div.find('div',{'class':'reviewer_position'}).text\n",
    "                domain = div.find_all('span',{'class':'reviewer_list__details-title'})\n",
    "                data['name']=name \n",
    "                data['position']=postion\n",
    "                data['domain'] =domain[0].text\n",
    "                if 'Employee' in domain[1].text:\n",
    "                    data['Employee NO']= domain[1].text\n",
    "                    data['location'] = domain[2].text\n",
    "                elif 'Employee' in domain[2].text:\n",
    "                    data['Employee NO']= domain[2].text\n",
    "                    data['location'] = domain[1].text\n",
    "\n",
    "                data_list.append(data)\n",
    "            driver.quit()\n",
    "            \n",
    "            if j+1 !=1:\n",
    "                driver = start()\n",
    "                url = f'?page={j+1}#'.join(\"https://clutch.co/profile/altario#highlights\".split('#'))\n",
    "                driver.get(url)\n",
    "                bs = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "                \n",
    "        \n",
    "    except:\n",
    "        driver.quit()\n",
    "        time.sleep(2)\n",
    "        print(\"Problem with ---->\",url)\n",
    "    \n",
    "    print(company_no)\n",
    "    company_no+=1\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert reviewer's data to table for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>domain</th>\n",
       "      <th>Employee NO</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Larysa Kruk</td>\n",
       "      <td>Project Manager, Audio Tour Mobile App</td>\n",
       "      <td>Software</td>\n",
       "      <td>1-10 Employees</td>\n",
       "      <td>Amsterdam, Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karmand Ahmad</td>\n",
       "      <td>Ganeral Manager, ZMC Cargo</td>\n",
       "      <td>Other Industry</td>\n",
       "      <td>201-500 Employees</td>\n",
       "      <td>Erbil, Iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prashant Parmar</td>\n",
       "      <td>President, Aspect Commercial Realty &amp; Business...</td>\n",
       "      <td>Real estate</td>\n",
       "      <td>1-10 Employees</td>\n",
       "      <td>Charlotte, North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Operational Director, InDhan PayGate</td>\n",
       "      <td>Software</td>\n",
       "      <td>11-50 Employees</td>\n",
       "      <td>Indore, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CEO, Venture Company</td>\n",
       "      <td>Consumer Products</td>\n",
       "      <td>11-50 Employees</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Andrea Mattei</td>\n",
       "      <td>Marketing Manager, Atena S.p.A.</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>51-200 Employees</td>\n",
       "      <td>Brescia, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Adrian Ireland</td>\n",
       "      <td>Founder &amp; CEO, Educational Institution</td>\n",
       "      <td>Education</td>\n",
       "      <td>1-10 Employees</td>\n",
       "      <td>Dover, Delaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Arel Sirin</td>\n",
       "      <td>CTO &amp; Founder, Sunshift Dev</td>\n",
       "      <td>IT Services</td>\n",
       "      <td>11-50 Employees</td>\n",
       "      <td>Montevideo, Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Vice President, Macro Polymers Pvt Ltd</td>\n",
       "      <td>Chemicals &amp; Biotechnology</td>\n",
       "      <td>201-500 Employees</td>\n",
       "      <td>Ahmedabad, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Antonella Portesi</td>\n",
       "      <td>Owner, Tecnocarpent Srl</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>11-50 Employees</td>\n",
       "      <td>Brescia, Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                           position  \\\n",
       "0         Larysa Kruk             Project Manager, Audio Tour Mobile App   \n",
       "1       Karmand Ahmad                         Ganeral Manager, ZMC Cargo   \n",
       "2     Prashant Parmar  President, Aspect Commercial Realty & Business...   \n",
       "3           Anonymous               Operational Director, InDhan PayGate   \n",
       "4           Anonymous                               CEO, Venture Company   \n",
       "..                ...                                                ...   \n",
       "88      Andrea Mattei                    Marketing Manager, Atena S.p.A.   \n",
       "89     Adrian Ireland             Founder & CEO, Educational Institution   \n",
       "90         Arel Sirin                        CTO & Founder, Sunshift Dev   \n",
       "91          Anonymous             Vice President, Macro Polymers Pvt Ltd   \n",
       "92  Antonella Portesi                            Owner, Tecnocarpent Srl   \n",
       "\n",
       "                       domain        Employee NO                   location  \n",
       "0                    Software     1-10 Employees     Amsterdam, Netherlands  \n",
       "1              Other Industry  201-500 Employees                Erbil, Iraq  \n",
       "2                 Real estate     1-10 Employees  Charlotte, North Carolina  \n",
       "3                    Software    11-50 Employees              Indore, India  \n",
       "4           Consumer Products    11-50 Employees     London, United Kingdom  \n",
       "..                        ...                ...                        ...  \n",
       "88                 Consulting   51-200 Employees             Brescia, Italy  \n",
       "89                  Education     1-10 Employees            Dover, Delaware  \n",
       "90                IT Services    11-50 Employees        Montevideo, Uruguay  \n",
       "91  Chemicals & Biotechnology  201-500 Employees           Ahmedabad, India  \n",
       "92              Manufacturing    11-50 Employees             Brescia, Italy  \n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [dict(t) for t in {tuple(d.items()) for d in data_list}]\n",
    "df = pd.DataFrame(data_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append data in previous excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('output.xlsx')\n",
    "df1 = pd.concat([df1, df], ignore_index=True, sort=False)\n",
    "df1=df1[df1['name']!='Anonymous'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to output.xlsx\n",
      "Total data till now 6432\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel\n",
    "excel_file_path = 'output.xlsx'\n",
    "df1.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data exported to {excel_file_path}\")\n",
    "print(f'Total data till now {len(df1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
